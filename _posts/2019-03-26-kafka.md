---
ID: 838
post_title: Kafka
author: admin
post_excerpt: ""
layout: post
permalink: https://cscourses.online/topics/kafka/
published: true
post_date: 2019-03-26 15:38:41
---
<h2>Kafka Introduction</h2>
<p>Kafka is a distributed publish/subscribe messaging systems that runs as a cluster. 
A single Kafka server is called a broker. Kafka brokers are designed to operate as part 
of a cluster. Kafka is able to seamlessly handle multiple producers and multiple consumers 
without interfering with each other.</p>
<p>Data in Kafka is replicated, persistent, and can be kept around as long as you like. </p>
<h3>Kafka Installation</h3>
<p>Kafka is a Java application, and can run on Windows, MacOS, and Linux, so make sure Java environment
is installed and set up. Kafka uses Zookeeper to store metadata about the Kafka cluster, and
consumer client details, so make sure Zookeeper is installed and configured.</p>
<pre>
$ tar -zxf kafka_2.11-0.9.0.1.tgz
$ mv kafka_2.11-0.9.0.1 /usr/local/kafka
$ mkdir /tmp/kafka-logs
$ /usr/local/kafka/bin/kafka-server-start.sh -daemon /usr/local/kafka/config/server.properties
$
## Create and verify a topic:
$ /usr/local/kafka/bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
$ /usr/local/kafka/bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic test
Topic:test PartitionCount:1 ReplicationFactor:1 Configs:
 Topic: test Partition: 0 Leader: 0 Replicas: 0 Isr: 0
$
## Produce messages to a test topic:
$ /usr/local/kafka/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
Test Message 1
Test Message 2
^D
$
## Consume messages from a test topic:
$ /usr/local/kafka/bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning
Test Message 1
Test Message 2
^C
Consumed 2 messages
$
</pre>
<h3>Kafka Broker Configuration</h3>
<ul>
<li>broker.id - an integer identifier. It must be unique within a single Kafka cluster </li>
<li>port - default Kafka listens on TCP port 9092</li>
<li>zookeeper.connect - the location used for storing the broker metadata.</li>
<li>log.dirs - Kafka persists all messages to disk, and these log segments are stored in the directories 
specified by log.dirs. </li>
<li>num.recovery.threads.per.data.dir - a configurable pool of threads for handling log segments. </li>
<li>auto.create.topics.enable - specifies that the broker should automatically create a topic.</li>
</ul>
<h2>Kafka Producers</h2>
<p>The simplest way to send a message is as follows,</p>
<pre>
ProducerRecord<String, String> record =
 new ProducerRecord<>("CustomerCountry", "Precision Products", "France");
try {
 producer.send(record);
} catch (Exception e) {
 e.printStackTrace();
}
</pre>
<h2>Kafka Consumers</h2>
<p>The following code snippet shows how to create a KafkaConsumer,</p>
<pre>
Properties props = new Properties();
props.put("bootstrap.servers", "broker1:9092,broker2:9092");
props.put("group.id", "CountryCounter");
props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
KafkaConsumer<String, String> consumer = new KafkaConsumer<String, String>(props);
</pre>
<p>Once we create a consumer, the next step is to subscribe to one or more topics.</p>
<pre>
consumer.subscribe(Collections.singletonList("customerCountries")); 
</pre>

<pre>
try {
 ConsumerRecords<String, String> records = consumer.poll(100);
 for (ConsumerRecord<String, String> record : records)
 {
    //processing
 }
} finally {
 consumer.close();
}
</pre>