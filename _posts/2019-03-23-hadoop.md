---
ID: 832
post_title: Hadoop
author: admin
post_excerpt: ""
layout: post
permalink: https://cscourses.online/topics/hadoop/
published: true
post_date: 2019-03-23 02:31:34
---
<!DOCTYPE html>
<html>
  <head>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <title></title>
  </head>
  <body>
    <h2>Hadoop Introdiction</h2>
    <p>Hadoop provides a reliable, 
scalable platform for storage and analysis
      big data.</p>
    <h3>Hadoop Installation</h3>
    <p>You can install Hadoop on a single machine to try it out.</p>
    <pre>java -version    
wget https://archive.apache.org/dist/hadoop/common/hadoop-3.2.0/hadoop-3.2.0.tar.gz
tar xzf hadoop-3.2.0.tar.gz
sudo mv hadoop-3.2.0 /usr/local/hadoop
</pre>
    <p>Change Hadoop configuration, add following line in vim
      /usr/local/hadoop/etc/hadoop/hadoop-env.sh</p>
    <pre>export JAVA_HOME=$(readlink -f /usr/bin/java | sed "s:bin/java::")</pre>
    <p>Verify Hadoop is ready.</p>
    <pre>$/usr/local/hadoop/bin/hadoop version</pre>
    <h2>MapReduce</h2>
    <p>MapReduce is a batch query processor which run an ad hoc query against
      the whole dataset and get the results in a reasonable time. MapReduce is
      fundamentally a batch processing system, and is not suitable for
      interactive analysis.</p>
    <p>MapReduce is a complement to a Relational Database Management System
      (RDBMS). MapReduce is a good fit for problems that need to analyze the
      whole dataset in a batch fashion, particularly for ad hoc analysis. An
      RDBMS is good for retrieval and update times of a relatively small amount
      of data. MapReduce suits applications where the data is written once and
      read many times, whereas a relational database is good for datasets that
      are continually updated.</p>
    <p>An example in Python.</p>
    <p>File mapper.py</p>
<pre lang="python">#!/usr/bin/python3
import sys
for line in sys.stdin:
  words = line.strip().split()
  for word in words:
    print('%s\t%s' % (word, 1))
</pre>    
    <p>File reducer.py</p>
<pre lang="python">
#!/usr/bin/python3
from operator import itemgetter
import sys

current_word = None
current_count = 0
word = None

for line in sys.stdin:
    line = line.strip()
    word, count = line.split('\t', 1)

    try:
        count = int(count)
    except ValueError:
        print("ValueError!")
        continue

    if current_word == word:
        current_count += count
    else:
        if current_word:
            print('%s\t%s' % (current_word, current_count))
        current_count = count
        current_word = word

if current_word == word:
    print ('%s\t%s' % (current_word, current_count))
</pre>    
  <p>File in input,</p>
   <pre>$cat input/*
foo foo quux labs foo bar quux</pre>
  <p>Command to run locally.</p>
<pre>/usr/local/hadoop/bin/hadoop \
  jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.2.0.jar \
  -mapper mapper.py \
  -reducer reducer.py \
  -input input \
  -output output</pre>
 <p>The output,</p>
<pre>$cat output/part-00000 
bar	1
foo	3
labs	1
quux	2
$</pre>
  </body>
</html>